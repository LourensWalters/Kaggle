{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"font-family:verdana; background-color:#C5D6FA\"><center>I. Titanic baseline models\n",
    "</center></h1>\n",
    "<p><center style=\"color:#1F4BA7; font-family:cursive;\">Prediction of survival rate using 9\n",
    "variables</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis we use the <b>Titanic Kaggle Competition</b> dataset found on the Kaggle Data\n",
    "Repository at the following location:\n",
    "\n",
    "<a href=https://www.kaggle.com/c/titanic/data>Titanic Kaggle Competition Dataset</a>\n",
    "\n",
    "The objective of the analysis is to classify survivors of the Titanic disaster of 1912 according to\n",
    "survival.\n",
    "\n",
    "We aim to achieve this by following the ML pipeline approach of deploying a variety of ML techniques\n",
    "to build a final predictive model. This particular analysis comprises 4 notebooks as follows:\n",
    "\n",
    " 1. <i>titanic_baseline</i> - <b>This notebook</b>, baseline predictive models (quick and dirty) to\n",
    " compare later results against\n",
    " 2. <i>titanic_eda</i> - Exploratory Descriptive Analysis (EDA)\n",
    " 3. <i>titanic_features</i> - Perform feature engineering\n",
    " 4. <i>titanic_final_model</i> - Final model\n",
    "\n",
    "We hope to gain valuable insights by following this process. The various steps in the process can be\n",
    "elaborated on as follows (the various notebooks will focus on different parts of the process as\n",
    "indicated):\n",
    "\n",
    "- Load data (<i>all notebooks</i>)\n",
    "- Prepare data\n",
    "    - Clean data (<i>notebook 2</i>)\n",
    "        - Missing values\n",
    "        - Outliers\n",
    "        - Erroneous values\n",
    "    - Explore data (<i>notebook 2</i>)\n",
    "        - Exploratory descriptive analysis (EDA)\n",
    "        - Correlation analysis\n",
    "        - Variable cluster analysis\n",
    "    - Transform Data (<i>notebook 3</i>)\n",
    "        - Engineer features\n",
    "        - Encode data\n",
    "        - Scale & normalise data\n",
    "        - Impute data (if not done in previous steps)\n",
    "        - Feature selection/ importance analysis\n",
    "- Build model (<i>notebooks 1 & 4</i>)\n",
    "    - Model selection\n",
    "    - Data sampling (validation strategy, imbalanced classification)\n",
    "    - Hyperparameter optimisation\n",
    "- Validate model (<i>notebooks 1 & 4</i>)\n",
    "    - Accuracy testing\n",
    "- Analysis of results (<i>notebook 1 & 4</i>)\n",
    "    - Response curves\n",
    "    - Accuracy analysis\n",
    "    - Commentary\n",
    "\n",
    "The data dictionary for this dataset is as follows:\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "|----------|------------|-----|\n",
    "| survival | Survival\t| 0 = No, 1 = Yes |\n",
    "| pclass   | Ticket class |\t1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "|sex | Sex | male, female |\n",
    "|Age | Age in years | Continuous |\n",
    "|sibsp | # of siblings / spouses aboard the Titanic | 0, 1, 2, ..|\n",
    "|parch | # of parents / children aboard the Titanic | 0, 1, 2 ..|\n",
    "|ticket | Ticket number | PC 17599, STON/O2. 3101282, 330877 |\n",
    "|fare | Passenger fare | Continuous |\n",
    "|cabin | Cabin number | C123, C85, E46 |\n",
    "|embarked | Port of Embarkation\t| C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "Let us start the analysis for <b>notebook 1</b>!\n",
    "\n",
    "Our approach for this notebook will be to take shortcuts i.e. drop variables that require\n",
    "pre-processing, e.g. unstructured text, or where replacement of missing values is required, without\n",
    "any thought to the best strategy. We will not do any feature engineering or attempt to understand\n",
    "the data (we will do this in the next notebook). We will rapidly build 4 models to get an idea of the\n",
    "strength of the signal in the data as well as where there might be issues with the data, or obvious\n",
    "areas for improvement for the model. The models we will build are the following:\n",
    "\n",
    " 1. Logistic regression: Bread and butter classification model - Aim is to obtain an idea of how a\n",
    " classical linear model performs\n",
    " 2. Multi-layer Perceptron (MLP): Understand how a simple non-linear model performs\n",
    " 3. Decision Tree: Provide visual analysis of variable importance and strength of association\n",
    " 4. Random Forest: Use model that good at dealing with unprocessed categorical variables in order to\n",
    " ascertain potential gains of pre-processing in next steps\n",
    "\n",
    "We will use the scikit-learn libraries to build the prototype models from first principles. In later\n",
    "notebooks we will use Keras and PyTorch to build the final models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-91d105365645>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Import libraries\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from patsy.highlevel import dmatrix\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from src.visualization.visualize_titanic import plot_confusion_matrix, plot_roc_curve, \\\n",
    "    plot_feature_importance, plot_feature_importance_log, plot_feature_importance_dec, plotVar, \\\n",
    "    plotAge, plotContinuous, plotCategorical, plot_learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, validation_curve, \\\n",
    "    GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"load\" style = \"font-family:verdana; background-color:#C5D6FA\"><center>Load Data</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "df_train = pd.read_csv('../data/external/train.csv', header = None, names = ['passenger_id',\n",
    "                      'survived', 'p_class', 'name', 'sex', 'age', 'sib_sp', 'parch',\n",
    "                      'ticket', 'fare', 'cabin', 'embarked'],\n",
    "                       index_col=False, usecols = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "                       skiprows=1, sep=',', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head(20)\n",
    "print(df_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "df_test = pd.read_csv('../data/external/test.csv', header = None, names = ['passenger_id',\n",
    "                     'p_class', 'name', 'sex', 'age', 'sib_sp', 'parch', 'ticket', 'fare',\n",
    "                     'cabin', 'embarked'],\n",
    "                      index_col=False, usecols = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                      skiprows=1, sep=',', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head(20)\n",
    "print(df_test.shape)\n",
    "df_orig = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to note is that the dataset read from csv file has 891 rows and 12 data columns. This\n",
    "is different to the Kaggle data dictionary claiming 891 rows and 10 data columns.\n",
    "\n",
    "The two extra fields are name and ticket. These unstructured text variables will require\n",
    "pre-processing and hence I leave them out for the moment. We will also leave cabin out, as it requires\n",
    "pre-processing too. Excluding the dependent variable we therefore have 9 feature variables for this\n",
    "analysis.\n",
    "\n",
    "Let us do minimal exploration of the data and then start building our baseline models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"clean\" style = \"font-family:verdana; background-color:#C5D6FA\"><center>Clean data\n",
    "</center></h1>\n",
    "<p><center style=\"color:#1F4BA7; font-family:cursive;\">Basic data cleaning, more\n",
    "to follow in next notebook...</center></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create first stab at an improvement, start with the obvious variables to create a quick model. Leave\n",
    "# ticket out for now, as some parsing will be necessary\n",
    "#df_train = df_train.loc[:, ['survived', 'p_class', 'sex', 'age', 'sib_sp', 'parch', 'fare',\n",
    "# 'embarked']]\n",
    "# We use will use all of the variables from here onwards.\n",
    "df_train = df_train.loc[:, ['survived', 'p_class', 'name', 'sex', 'age', 'sib_sp', 'parch',\n",
    "                            'ticket', 'fare', 'cabin', 'embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_test = df_test.loc[:, ['p_class', 'name', 'sex', 'age', 'sib_sp', 'parch', 'ticket',\n",
    "                          'fare', 'cabin', 'embarked']]\n",
    "#df_test = df_test.loc[:, ['p_class', 'sex', 'age', 'sib_sp', 'parch', 'fare', 'embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Type of data\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Type of data\n",
    "df_test.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the high level checks we can see that there are missing values in the following fields: age, fare\n",
    "and embarked.\n",
    "\n",
    "We will impute these values with simple measures of centrality for these variables (median, mode) at\n",
    "present. During the next stage of the analysis we will revisit this decision by performing EDA before\n",
    "removing missing values in order to make a more informed decision, for now we forge ahead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df_train.isnull().sum()\n",
    "\n",
    "# Actual null values\n",
    "df_train[df_train.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check for null values for test data\n",
    "print(df_test.isnull().sum())\n",
    "# Actual null values\n",
    "df_test[df_test.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed 177 null values for <i>age</i> and 2 for <i>embarked</i> for <i>training data</i> and 86\n",
    "null values for <i>age</i> and 1 for <i>fare</i> for <i>testing data</i>.\n",
    "\n",
    "We will substitute missing values for age with the median values to allow for skewness or outliers in\n",
    "the distribution as it is a robust measure for central tendency. For embarked we will use the mode\n",
    "seeing as it is a categorical variable with few classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Replace missing values for training set\n",
    "df_train = df_train.copy()\n",
    "median = df_train['age'].median()\n",
    "df_train['age'].fillna(median, inplace=True)\n",
    "print(\"Number of null values in age column: {}\".format(df_train['age'].isnull().sum()))\n",
    "\n",
    "mode = df_train['embarked'].mode()\n",
    "df_train['embarked'].fillna(mode.iloc[0], inplace=True)\n",
    "print(\"Number of null values in embarked column: {}\".format(df_train['embarked'].isnull().sum()))\n",
    "print(\"Dataframe dimension: {}\".format(df_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Replace missing values for test set\n",
    "df_test = df_test.copy()\n",
    "median = df_test['age'].median()\n",
    "df_test['age'].fillna(median, inplace=True)\n",
    "print(\"Number of null values in age column: {}\".format(df_test['age'].isnull().sum()))\n",
    "\n",
    "median = df_test['fare'].median()\n",
    "df_test['fare'].fillna(median, inplace=True)\n",
    "print(\"Number of null values in fare column: {}\".format(df_test['fare'].isnull().sum()))\n",
    "print(\"Dataframe dimension: {}\".format(df_test.shape))\n",
    "df_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the null values have been removed. We now have a dataset ready for further analysis -\n",
    "albeit a bit of a black box hack. We will now do some very limited EDA just to get a feel for the data\n",
    " as previously discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"explore\" style = \"font-family:verdana; background-color:#C5D6FA\"><center>Explore data\n",
    "</center></h1>\n",
    "<p><center style=\"color:#1F4BA7; font-family:cursive;\">Basic exploration, more\n",
    "to follow in next notebook...</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by looking at the number of unique records per variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(df_train.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no columns with only one value. We therefore retain all columns for ML purposes as there is\n",
    "enough variability to warrant using the data. There are many variables with fewer than 10 levels which\n",
    " could be considered as categorical. Based on our initial assessment of the data we will work with\n",
    " levels of measurement for the data as follows:\n",
    "\n",
    "- p_class (ordinal) - we will revisit type of encoding later\n",
    "- sex (binary) - recode (female - yes or no)\n",
    "- age (continuous)\n",
    "- sib_sp (ordinal) - check correlation - revisit encoding\n",
    "- parch (ordinal) - check correlation - revisit encoding\n",
    "- fare (continuous)\n",
    "- embarked (nominal) - recode (one hot encode) - probably categorical\n",
    "\n",
    "At this point it seems as if we mainly have nominal and binary categorical data. We need to One Hot\n",
    "Encode one variable i.e. embarked. We will leave the ordinal data as is for the initial analysis i.e.\n",
    "label encode it. Next we look at the distribution of the data.\n",
    "\n",
    "We now separate continuous and categorical variables for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Separate continuous and categorical variables\n",
    "names_con = ('fare', 'age')\n",
    "names_con_plot = ('survived', 'fare', 'age')\n",
    "names_cat = ('survived', 'p_class', 'sex', 'sib_sp', 'parch', 'embarked')\n",
    "names_cat_test = ('p_class', 'sex', 'sib_sp', 'parch', 'embarked')\n",
    "\n",
    "df_train_con = df_train.loc[:, names_con]\n",
    "df_train_con_plot = df_train.loc[:, names_con_plot]\n",
    "df_train_cat = df_train.loc[:, names_cat]\n",
    "\n",
    "df_test_con = df_test.loc[:, names_con]\n",
    "df_test_cat = df_test.loc[:, names_cat_test]\n",
    "\n",
    "# Plotting label dictionary\n",
    "plot_con = [('fare', 'Fare'),\n",
    "            ('age', 'Age')]\n",
    "plot_con_plot = [('survived', 'Survived'),\n",
    "            ('fare', 'Fare'),\n",
    "            ('age', 'Age')]\n",
    "plot_cat = ['survived', ['Yes', 'No'],\n",
    "            ('p_class', ['1st', '2nd', '3rd']),\n",
    "            ('sex', ['Male', 'Female']),\n",
    "            ('sib_sp', '# siblings or spouses'),\n",
    "            ('parch', '# parents or children'),\n",
    "            ('embarked', ['Cherbourg', 'Queenstown', 'Southampton'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that we have two candidates for continuous variables here (age and fare). With all the\n",
    "categorical variables present, it is likely that a tree model would be better suited to this problem\n",
    "unless significant feature engineering on categorical features is performed to ensure features are\n",
    "optimally encoded, transformed and scaled for a linear model or neural network.\n",
    "\n",
    "Let's continue with the high level analysis.\n",
    "\n",
    "The overall survival rate was as follows (based on the training dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot outcome counts.a\n",
    "outcome_counts = df_train_cat['survived'].value_counts(normalize = True)\n",
    "\n",
    "base_color = sns.color_palette()[0]\n",
    "ax = sns.barplot(x=outcome_counts.index, y=outcome_counts.values, alpha=0.9, color=base_color)\n",
    "ax.xaxis.label.set_size(20)\n",
    "#ax.title.set_size(10)\n",
    "\n",
    "legend_labels = ['Died', 'Survived']\n",
    "_ = plt.xticks(fontsize=14, ticks=ax.get_xticks(), labels=legend_labels)\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "_ = plt.yticks([])\n",
    "\n",
    "_ = plt.title('Survival Rate', fontsize=15, pad=30)\n",
    "\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    _ = ax.annotate(f'{height:.0%}', (x + width/2, y + height*1.02), ha='center', fontsize=15)\n",
    "\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The survival statistics are as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(df_train_cat['survived'].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "#print(df_train_cat['survived'].value_counts(normalize = True).mul(100).round(1).astype(str) + '%')\n",
    "#print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that 38% of passengers survived and 62% died. These statistics correspond with the narrative on survival\n",
    "rate quoted in the background information on Kaggle. There it is quoted that around 32% survived and 68% died. The\n",
    "sample we are working with is thus representative of the overall population, which is important to note.\n",
    "\n",
    "We observe that the target variable contains unbalanced classes. We need to consider revisiting the unbalanced\n",
    "classes at a later stage - depending on the accuracy of our models. For now, we will forge ahead.\n",
    "\n",
    "Next we will consider class level counts for categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variable overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Class level counts for categorical variables.\n",
    "for variable in names_cat:\n",
    "    print(df_train_cat[variable].value_counts(normalize = True).mul(100).round(1).astype(str) + '%')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Bar chart plot of categorical variables.\n",
    "fig, ax = plt.subplots(2, 3, figsize=(20, 15));\n",
    "base_color = sns.color_palette()[0]\n",
    "for variable, subplot in zip(names_cat, ax.flatten()):\n",
    "    subplot.xaxis.label.set_size(24)\n",
    "    subplot.yaxis.label.set_size(24)\n",
    "    subplot.tick_params('y', labelsize = 20);\n",
    "    subplot.tick_params('x', labelsize = 20);\n",
    "    cat_order = df_train_cat[variable].value_counts().index\n",
    "    cp = sns.countplot(data = df_train_cat, x = variable, order = cat_order, ax=subplot, color=base_color)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the categorical variables we observe that there were approximately twice as many passengers in class 3 than either\n",
    "class 1 or 2. We also observe that there were nearly twice as many males as females on the Titanic. We also observe\n",
    "that more than two thirds of passengers did not have any siblings on board. Likewise we observe that more than two\n",
    "thirds did not have a father or child on board.\n",
    "\n",
    "It is therefore fair to say that the majority of passengers were either couples or single travellers without children\n",
    ". In the case where families did travel, the majority of families had one or two children. Very few families with\n",
    "more children were on board the Titanic.\n",
    "\n",
    "We also see that more than two thirds of passengers departed from Southampton.\n",
    "\n",
    "Many of these variables could contribute o correlation with survival at face value e.g. it stands to reason that\n",
    "preference would have been given in lifeboats to women and children, and that more affluent travellers would have had\n",
    "access to better lifeboats. We will however test these hypotheses in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous variable overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig_age, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 6), squeeze=False)\n",
    "_ = plotAge(df=df_train_con_plot, axes=axes, single_plot=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the age distribution plot we can see that more children under the age of 15 survived than died in the incident. \n",
    "We can see that more individuals between the ages of 20 and 40 died than survived. We can also see that more \n",
    "individuals above the age of 80 survived compared to dying.\n",
    "\n",
    "We can also see that the majority of individuals on the cruise were between the ages of 20 to 40. There were fewer\n",
    "teenagers compared to children under 10. There were comparatively fewer elderly people on board i.e. above 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 5 number summary.\n",
    "df_train_con.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fare distribution is severely skewed to the right. The kurtosis of the plot is very high with most values\n",
    "clustered closely around the median value of 14. There was a non-significant but relatively smaller number of fares\n",
    "spread between teh values of 30 and 500.\n",
    "\n",
    "The age distribution was as previously discussed, with a minimum of 6 months and maximum of 80 years old. The\n",
    "distribution is fairly symmetrical with a slight skew to the right. There is a young child bump to the left of the\n",
    "distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Continuous density plot\n",
    "fig_continuous, axes = plt.subplots(nrows=len(names_con_plot)-1, ncols=2, figsize=(15, 12))\n",
    "\n",
    "# Plot frequency plot/ histogram\n",
    "_ = sns.histplot(x=plot_con[0][0], kde=True, data=df_train_con_plot, ax=axes[0][0], bins=40);\n",
    "_ = axes[0][0].set(xlabel=plot_con[0][1], ylabel='Density');\n",
    "axes[0][0].xaxis.label.set_size(24)\n",
    "axes[0][0].yaxis.label.set_size(24)\n",
    "axes[0][0].tick_params('y', labelsize = 20);\n",
    "axes[0][0].tick_params('x', labelsize = 20);\n",
    "\n",
    "# Plot violin plot\n",
    "_ = sns.violinplot(x='survived', y=plot_con[0][0], data=df_train_con_plot, ax=axes[0][1]);\n",
    "_ = axes[0][1].set(xlabel='', ylabel=plot_con[0][1]);\n",
    "axes[0][1].xaxis.label.set_size(24)\n",
    "axes[0][1].yaxis.label.set_size(24)\n",
    "axes[0][1].tick_params('y', labelsize = 20);\n",
    "axes[0][1].tick_params('x', labelsize = 20);\n",
    "_ = axes[0][1].set_xticklabels(['Died', 'Survived'])\n",
    "\n",
    "# Plot frequency plot/ histogram\n",
    "_ = sns.histplot(x=plot_con[1][0], kde=True, data=df_train_con_plot, ax=axes[1][0], bins=40);\n",
    "_ = axes[1][0].set(xlabel=plot_con[1][1], ylabel='Density');\n",
    "axes[1][0].xaxis.label.set_size(24)\n",
    "axes[1][0].yaxis.label.set_size(24)\n",
    "axes[1][0].tick_params('y', labelsize = 20);\n",
    "axes[1][0].tick_params('x', labelsize = 20);\n",
    "\n",
    "# Plot violin plot\n",
    "_ = sns.violinplot(x='survived', y=plot_con[1][0], data=df_train_con_plot, ax=axes[1][1]);\n",
    "_ = axes[1][1].set(ylabel=plot_con[1][1], xlabel='');\n",
    "axes[1][1].xaxis.label.set_size(24)\n",
    "axes[1][1].yaxis.label.set_size(24)\n",
    "axes[1][1].tick_params('y', labelsize = 20);\n",
    "axes[1][1].tick_params('x', labelsize = 20);\n",
    "_ = axes[1][1].set_xticklabels(['Died', 'Survived'])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The violin plot for <i>fare</i> indicates that there is correlation between fare and survival as more people paying a\n",
    "low fare died and chances of survival increased for higher fares, as well as lower fares close to zero (possibly for\n",
    "children travelling at very low cost).\n",
    "\n",
    "The plot for <i>age</i> indicates a similar pattern with higher survival for children below 10 and higher mortality\n",
    "between ages of 20 and 40. The relative likelihood of survival increases again around 40 years of age as you go into\n",
    "the older ages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Boxplot of continuous variables\n",
    "medianprops = {'color': 'magenta', 'linewidth': 2}\n",
    "boxprops = {'color': 'black', 'linestyle': '-', 'linewidth': 2}\n",
    "whiskerprops = {'color': 'black', 'linestyle': '-', 'linewidth': 2}\n",
    "capprops = {'color': 'black', 'linestyle': '-', 'linewidth': 2}\n",
    "flierprops = {'color': 'black', 'marker': 'x', 'markersize': 20}\n",
    "\n",
    "_ = df_train_con.plot(kind='box', subplots=True, figsize=(20, 8), layout=(1,2), fontsize = 20, medianprops=medianprops,\n",
    "                    boxprops=boxprops, whiskerprops=whiskerprops, capprops=capprops, flierprops=flierprops);\n",
    "_ = plt.tight_layout();\n",
    "_ = plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of the <i>fare</i> and <i>age</i> variables show that fare is skewed heavily to the right, with the\n",
    "median skewed to the left of the distribution as expected. The values in the final quintile are spread over wide area\n",
    "with quite a few outliers. This distribution is heavy tailed, as can be expected of many financial distributions.\n",
    "\n",
    "The <i>age</i> distribution is fairly symmetrical, with a few outliers to the right, but nothing out of the ordinary.\n",
    "Most of the values are bundled symmetrically around the median of 28, which is quite a young age for the average\n",
    "traveller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"transform\" style = \"font-family:verdana; background-color:#C5D6FA\"><center>Transform\n",
    "variables\n",
    "</center></h1>\n",
    "<p><center style=\"color:#1F4BA7; font-family:cursive;\">Imputation of missing\n",
    "values, scaling of variables and creating interaction terms</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from all our analyses that there are many categorical variables strongly\n",
    "correlated with survival. It is also clear that there are many strong variable interactions\n",
    "in the data.\n",
    "\n",
    "It therefore makes sense to experiment with binning of the two continuous variables i.e. age\n",
    " and fare and to manually perform some interactions modelling to see if we can obtain more\n",
    " consistent results with our predictive models.\n",
    "\n",
    "We have already looked at the age variable in detail before, let's have another look at the\n",
    "fare variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig_fare, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 6), squeeze=False)\n",
    "\n",
    "_ = sns.kdeplot(data=df_train_con_plot.loc[(df_train_con_plot['survived'] == 0), 'fare'],\n",
    "                shade = True, label = 'Died')\n",
    "_ = sns.kdeplot(data=df_train_con_plot.loc[(df_train_con_plot['survived'] == 1), 'fare'],\n",
    "                shade = True, label = 'Survived')\n",
    "_ = plt.xlabel('Fare', fontsize=20)\n",
    "_ = plt.ylabel('Density', fontsize=20)\n",
    "_ = plt.xticks(fontsize=20)\n",
    "_ = plt.yticks(fontsize=20)\n",
    "_ = plt.legend(fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can bin this variable quite easily.\n",
    "\n",
    "As age and fare have missing values, we need to impute this at time of model building to\n",
    "avoid data leakage. We will therefore go ahead with the model building process and bin these\n",
    " variables after missing values have been replaced.\n",
    "\n",
    "We will now build the following models as previously discussed:\n",
    "\n",
    " 1. Logistic regression\n",
    " 2. Multi-layer Perceptron (MLP)\n",
    " 3. Decision Tree\n",
    " 4. Random Forest\n",
    "\n",
    "Our strategy is to build our own <i>validation strategy</i> based on the training set for which\n",
    "we have labels. We will do this by splitting this set into training and testing sets according to\n",
    "a 75%/ 25% split. Any hyper-parameter optimisation will be done by using <i>cross validation</i>\n",
    "on the 75% test set. The 25% testing set will be used for our final test before we apply the\n",
    "results to the provided test set for submission.\n",
    "\n",
    "We therefore now start by splitting the response and features for the training set as previously\n",
    "discussed.\n",
    "\n",
    "We will be using this dataset for all our models from here onwards. We also perform minor\n",
    "transformations such as encoding the <i>sex</i> variable for test and training sets. We also One\n",
    "Hot Encode the <i>embarked</i> variable. We drop one of the categories for embarked to avoid\n",
    "multi-collinearity (dummy variable trap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train['age_missing'] = df_train.apply(lambda row: 1 if np.isnan(row['age']) else 0, axis=1)\n",
    "df_test['age_missing'] = df_test.apply(lambda row: 1 if np.isnan(row['age']) else 0, axis=1)\n",
    "\n",
    "# We will now transform some variables by grouping categories together based on our EDA\n",
    "# analysis. We also encode categorical variables to numeric values in order to do the ML\n",
    "# analysis.\n",
    "# These transformations would not result in data leakage, and can hence be done before we\n",
    "# split the data into training and testing sets.\n",
    "\n",
    "# Make a copy of original dataset before imputation - we need the original for further\n",
    "# analysis.\n",
    "df_train_trans = df_train.copy()\n",
    "df_test_trans = df_test.copy()\n",
    "\n",
    "# Creating Deck field from the first letter of the cabin field (we create a new category for\n",
    "# missing, which is called M). As this is a categorical variable we will leave the missing\n",
    "# value field as is.\n",
    "df_train_trans['deck'] = df_train_trans['cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "df_test_trans['deck'] = df_test_trans['cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# There is only one passenger on deck T and the test set has no values for deck T.\n",
    "# The closest category is deck 'A' (checking on deck arrangements image found via Google), so\n",
    "# we change all occurrences of T to A.\n",
    "idx = df_train_trans[df_train_trans['deck'] == 'T'].index\n",
    "df_train_trans.loc[idx, 'deck'] = 'A'\n",
    "\n",
    "## Some of the classes have very few values, we group adjacent classes together.\n",
    "df_train_trans['deck'] = df_train_trans['deck'].replace(['B', 'D', 'E'], 'BDE')\n",
    "df_train_trans['deck'] = df_train_trans['deck'].replace(['A', 'G'], 'AG')\n",
    "df_train_trans['deck'] = df_train_trans['deck'].replace(['C', 'F'], 'FG')\n",
    "\n",
    "df_test_trans['deck'] = df_test_trans['deck'].replace(['B', 'D', 'E'], 'BDE')\n",
    "df_test_trans['deck'] = df_test_trans['deck'].replace(['A', 'G'], 'AG')\n",
    "df_test_trans['deck'] = df_test_trans['deck'].replace(['C', 'F'], 'FG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Next we extract the title variable from the name field\n",
    "df_train_trans['title'] = df_train_trans['name'].str.split(', ', expand=True)[1].str.split('.',\n",
    "                                                                            expand=True)[0]\n",
    "# Next we extract the title variable from the name field\n",
    "df_test_trans['title'] = df_test_trans['name'].str.split(', ', expand=True)[1].str.split('.',\n",
    "                                                                            expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train_trans['is_married'] = 0\n",
    "df_train_trans['is_married'].loc[df_train_trans['title'] == 'Mrs'] = 1\n",
    "\n",
    "df_test_trans['is_married'] = 0\n",
    "df_test_trans['is_married'].loc[df_test_trans['title'] == 'Mrs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train_trans['title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\n",
    "df_test_trans['title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\n",
    "\n",
    "df_train_trans['title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer', 'Rev',\n",
    "                                 'Dr'], 'Mr', inplace=True)\n",
    "df_test_trans['title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer', 'Rev',\n",
    "                                'Dr'], 'Mr', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train_trans['sex'].value_counts()\n",
    "# Transform sex variable - don't need one hot encoding as variable is binary\n",
    "df_train_trans['sex'] = df_train_trans['sex'].apply(lambda x: 1 if x == 'female' else 0)\n",
    "# Same transformation for test set - don't need one hot encoding as variable is binary\n",
    "df_test_trans['sex'] = df_test_trans['sex'].apply(lambda x: 1 if x == 'female' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Replace embarked with mode training set - no values missing in test set, so not required\n",
    "# to further impute. Some leakage takes place here, but only one value so not important -\n",
    "# TODO: fix this, just as a matter of principle.\n",
    "train_emb_mode = df_train_trans['embarked'].mode()\n",
    "df_train_trans['embarked'].fillna(train_emb_mode.iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create family size feature\n",
    "df_train_trans['fam_num'] = df_train_trans['sib_sp'] + df_train_trans['parch'] + 1\n",
    "df_test_trans['fam_num'] = df_test_trans['sib_sp'] + df_test_trans['parch'] + 1\n",
    "\n",
    "# Create family size groupings\n",
    "df_train_trans['fam_size'] = pd.cut(df_train_trans.fam_num, [0,1,4,7,11], labels=['single',\n",
    "                           'small', 'large', 'very_large'])\n",
    "df_test_trans['fam_size'] = pd.cut(df_test_trans.fam_num, [0,1,4,7,11], labels=['single',\n",
    "                           'small', 'large', 'very_large'])\n",
    "\n",
    "# Now we One Hot Encode Categorical variables. We leave the dimension variables for now, as\n",
    "# we might generate some cross terms later. We don't One Hot Encode variables with missing\n",
    "# values e.g. age, as we will impute these during training, and will One Hot Encode at that\n",
    "# stage.\n",
    "\n",
    "# Transform embarked and deck variables for training set\n",
    "categorical_cols = ['embarked', 'deck', 'title', 'p_class', 'fam_size']\n",
    "df_train_trans['dim_embarked'] = df_train_trans['embarked']\n",
    "df_train_trans['dim_deck'] = df_train_trans['deck']\n",
    "df_train_trans['dim_title'] = df_train_trans['title']\n",
    "df_train_trans['dim_p_class'] = df_train_trans['p_class']\n",
    "df_train_trans['dim_fam_size'] = df_train_trans['fam_size']\n",
    "df_train_trans = pd.get_dummies(df_train_trans, columns = categorical_cols, drop_first=True)\n",
    "\n",
    "# Transform embarked and deck variables for test set\n",
    "df_test_trans['dim_embarked'] = df_test_trans['embarked']\n",
    "df_test_trans['dim_deck'] = df_test_trans['deck']\n",
    "df_test_trans['dim_title'] = df_test_trans['title']\n",
    "df_test_trans['dim_p_class'] = df_test_trans['p_class']\n",
    "df_test_trans['dim_fam_size'] = df_test_trans['fam_size']\n",
    "df_test_trans = pd.get_dummies(df_test_trans, columns = categorical_cols, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now we create a variable\n",
    "df_train_trans['ticket_freq'] = df_train_trans.groupby('ticket')['ticket'].transform('count')\n",
    "df_test_trans['ticket_freq'] = df_test_trans.groupby('ticket')['ticket'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train_trans['ticket_freq'] = df_train_trans['ticket_freq'].apply(lambda x: 1 if x == 1\n",
    "else 0)\n",
    "# Same transformation for test set - don't need one hot encoding as variable is binary\n",
    "df_test_trans['ticket_freq'] = df_test_trans['ticket_freq'].apply(lambda x: 1 if x == 1\n",
    "else 0)\n",
    "\n",
    "df_train_trans['ticket_freq'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "names_all = list(df_train_trans.columns)\n",
    "#print(names_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'names_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-526d3f2e74fc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;31m# These change depending on prior analyses\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mnames_cat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnames_all\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdrop_cols\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mnames_cat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mremove\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'names_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Update dataframe fieldname values\n",
    "drop_cols = ['name', 'sib_sp', 'parch', 'ticket',\n",
    "       'cabin', 'age_missing', 'fam_num', 'dim_embarked', 'dim_deck',\n",
    "       'dim_title', 'dim_p_class', 'dim_fam_size']\n",
    "\n",
    "# These stay static\n",
    "names_con = ('fare', 'age')\n",
    "names_con_plot = ('survived', 'fare', 'age')\n",
    "\n",
    "# These change depending on prior analyses\n",
    "names_cat = names_all.copy()\n",
    "for x in drop_cols:\n",
    "    names_cat.remove(x)\n",
    "for x in ['survived', 'age', 'fare']:\n",
    "    names_cat.remove(x)\n",
    "\n",
    "print(\"names_cat: {}\".format(names_cat))\n",
    "\n",
    "names_cat_plot = names_all.copy()\n",
    "for x in drop_cols:\n",
    "    names_cat_plot.remove(x)\n",
    "for x in ['age', 'fare']:\n",
    "    names_cat_plot.remove(x)\n",
    "\n",
    "for x in drop_cols:\n",
    "    names_all.remove(x)\n",
    "for x in ['survived']:\n",
    "    names_all.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Group response values to form binary response\n",
    "y = df_train_trans.loc[:, 'survived']\n",
    "\n",
    "# Split data into features (X) and response (y)\n",
    "X = df_train_trans.loc[:, names_all]\n",
    "\n",
    "# Consider using another dataframe for applying testing\n",
    "df_test_trans = df_test_trans.loc[:, names_all]\n",
    "\n",
    "# Put the response y into an array\n",
    "y = np.ravel(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split, impute missing values and transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data into training and test sets according to a 75/ 25% split. We next\n",
    "impute missing values without data leakage on the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "#print('Percentage holdout data: {}%'.format(round(100*(len(X_test)/len(X)),0)))\n",
    "names_train = X.columns\n",
    "\n",
    "# Replace fare in test set with median from train set - to prevent data leakage.\n",
    "median_fare = X_train['fare'].median()\n",
    "df_test_trans['fare'].fillna(median_fare, inplace=True)\n",
    "\n",
    "# Replace missing values for training set\n",
    "print(\"Number of null values in age column: {}\".format(X_train['age'].isnull().sum()))\n",
    "\n",
    "# Define imputer\n",
    "imputer = KNNImputer()\n",
    "# fit on the dataset\n",
    "imputer.fit(X_train)\n",
    "# transform the dataset\n",
    "X_train_array = imputer.transform(X_train)\n",
    "# summarize total missing\n",
    "#print('Missing: %d' % sum(isnan(X_train).flatten()))\n",
    "X_train = pd.DataFrame(X_train_array, columns=names_train)\n",
    "\n",
    "X_test_array = imputer.transform(X_test)\n",
    "# summarize total missing\n",
    "#print('Missing: %d' % sum(isnan(X_test).flatten()))\n",
    "X_test = pd.DataFrame(X_test_array, columns=names_train)\n",
    "\n",
    "\n",
    "# Now we fit and transform for the final model.\n",
    "# Fit and apply to the final dataset: TODO: Test whether rebuilding model on complete set\n",
    "#  performs better\n",
    "#imputer.fit(X)\n",
    "\n",
    "X_array = imputer.transform(X)\n",
    "X = pd.DataFrame(X_array, columns=names_train)\n",
    "\n",
    "# summarize total missing\n",
    "#print('Missing: %d' % sum(isnan(X).flatten()))\n",
    "df_test_trans_array = imputer.transform(df_test_trans)\n",
    "# summarize total missing\n",
    "#print('Missing: %d' % sum(isnan(df_test_trans).flatten()))\n",
    "df_test_trans = pd.DataFrame(df_test_trans_array, columns=names_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Binning fare: TODO: fix problem with ranges not understood and undercounting\n",
    "fare_bins= [0, 8, 15, 30, 100, 300, 520]\n",
    "labels = ['very_low', 'low', 'average', 'above_average', 'high', 'very_high']\n",
    "df_train['fare_bin'] = pd.cut(df_train['fare'], bins=fare_bins, labels=labels, right=False)\n",
    "df_train_trans['fare_bin'] = pd.cut(df_train_trans['fare'], bins=fare_bins, labels=labels,\n",
    "                                    right=False)\n",
    "X_train['dim_fare'] = X_train['fare']\n",
    "X_train['dim_age'] = X_train['age']\n",
    "X_train['dim_ticket_freq'] = X_train['ticket_freq']\n",
    "X_test['dim_fare'] = X_test['fare']\n",
    "X_test['dim_age'] = X_test['age']\n",
    "X_test['dim_ticket_freq'] = X_test['ticket_freq']\n",
    "df_test_trans['dim_fare'] = df_test_trans['fare']\n",
    "df_test_trans['dim_age'] = df_test_trans['age']\n",
    "df_test_trans['dim_ticket_freq'] = df_test_trans['ticket_freq']\n",
    "\n",
    "X_train['fare_bin'] = pd.cut(X_train['fare'], bins=fare_bins, labels=labels, right=False)\n",
    "X_test['fare_bin'] = pd.cut(X_test['fare'], bins=fare_bins, labels=labels,\n",
    "                                    right=False)\n",
    "df_train_trans['fare_bin'] = pd.cut(df_train_trans['fare'], bins=fare_bins, labels=labels,\n",
    "                                   right=False)\n",
    "df_test_trans['fare_bin'] = pd.cut(df_test_trans['fare'], bins=fare_bins, labels=labels,\n",
    "                                   right=False)\n",
    "\n",
    "#Binning age: TODO: fix problem with ranges not understood and undercounting\n",
    "bins= [0, 4, 13, 20, 40, 60, 110]\n",
    "labels = ['infant','child','teen','adult', 'middle_aged', 'elderly']\n",
    "#df_train['age_bin'] = pd.cut(df_train['age'], bins=bins, labels=labels, right=False)\n",
    "#df_train_trans['age_bin'] = pd.cut(df_train_trans['age'], bins=bins, labels=labels, right=False)\n",
    "X_train['age_bin'] = pd.cut(X_train['age'], bins=bins, labels=labels, right=False)\n",
    "X_test['age_bin'] = pd.cut(X_test['age'], bins=bins, labels=labels, right=False)\n",
    "df_train_trans['age_bin'] = pd.cut(df_train_trans['age'], bins=bins, labels=labels,\n",
    "                                   right=False)\n",
    "df_test_trans['age_bin'] = pd.cut(df_test_trans['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "#\n",
    "X_train['dim_age_bin'] = X_train['age_bin']\n",
    "X_train['dim_fare_bin'] = X_train['fare_bin']\n",
    "X_test['dim_age_bin'] = X_test['age_bin']\n",
    "X_test['dim_fare_bin'] = X_test['fare_bin']\n",
    "\n",
    "# Transform embarked and deck variables for training set - try not binning fare\n",
    "#binning_cols = ['fare_bin', 'age_bin', 'ticket_freq']\n",
    "binning_cols = ['age_bin', 'fare_bin']\n",
    "X_train = pd.get_dummies(X_train, columns = binning_cols, drop_first=True)\n",
    "\n",
    "# Transform embarked and deck variables for testing set\n",
    "#binning_cols = ['fare_bin', 'age_bin', 'ticket_freq']\n",
    "binning_cols = ['age_bin', 'fare_bin']\n",
    "X_test = pd.get_dummies(X_test, columns = binning_cols, drop_first=True)\n",
    "\n",
    "# Transform embarked and deck variables for test set\n",
    "df_train_trans['dim_age_bin'] = df_train_trans['age_bin']\n",
    "df_train_trans['dim_fare_bin'] = df_train_trans['fare_bin']\n",
    "\n",
    "df_test_trans['dim_age_bin'] = df_test_trans['age_bin']\n",
    "df_test_trans['dim_fare_bin'] = df_test_trans['fare_bin']\n",
    "\n",
    "df_train_trans = pd.get_dummies(df_train_trans, columns = binning_cols, drop_first=True)\n",
    "df_test_trans = pd.get_dummies(df_test_trans, columns = binning_cols, drop_first=True)\n",
    "\n",
    "# Hack to fix ticket_freq distribution: TODO: Fix this.\n",
    "#df_test_trans['ticket_freq_6.0'] = 0\n",
    "#df_test_trans['ticket_freq_7.0'] = 0\n",
    "\n",
    "#X_train.drop('age', axis=1, inplace=True)\n",
    "#X_test.drop('age', axis=1, inplace=True)\n",
    "#df_test_trans.drop('age', axis=1, inplace=True)\n",
    "#df_train_trans.drop('age', axis=1, inplace=True)\n",
    "#X_train.drop('fare', axis=1, inplace=True)\n",
    "#X_test.drop('fare', axis=1, inplace=True)\n",
    "#df_test_trans.drop('fare', axis=1, inplace=True)\n",
    "#df_train_trans.drop('fare', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train, df_train_trans[['dim_deck']],left_index=True, right_index=True)\n",
    "\n",
    "# create dummy variables, and their interactions: TODO: Check if deck is better cross-term\n",
    "X_train_interactions = \\\n",
    "    dmatrix('C(dim_deck) : C(sex)', X_train,\n",
    "              return_type=\"dataframe\")\n",
    "X_train_interactions.drop('Intercept', inplace=True, axis=1)\n",
    "X_train = pd.concat([X_train, X_train_interactions], axis=1)\n",
    "\n",
    "X_train.drop('sex', axis=1, inplace=True)\n",
    "X_train.drop('dim_fare', axis=1, inplace=True)\n",
    "X_train.drop('dim_age', axis=1, inplace=True)\n",
    "X_train.drop('dim_fare_bin', axis=1, inplace=True)\n",
    "X_train.drop('dim_age_bin', axis=1, inplace=True)\n",
    "X_train.drop('dim_deck', axis=1, inplace=True)\n",
    "X_train.drop('dim_ticket_freq', axis=1, inplace=True)\n",
    "\n",
    "X_test = pd.merge(X_test, df_train_trans[['dim_deck']],left_index=True, right_index=True)\n",
    "X_test_interactions = \\\n",
    "    dmatrix('C(dim_deck) : C(sex)', X_test,\n",
    "              return_type=\"dataframe\")\n",
    "X_test_interactions.drop('Intercept', inplace=True, axis=1)\n",
    "X_test = pd.concat([X_test, X_test_interactions], axis=1)\n",
    "\n",
    "X_test.drop('sex', axis=1, inplace=True)\n",
    "X_test.drop('dim_fare', axis=1, inplace=True)\n",
    "X_test.drop('dim_age', axis=1, inplace=True)\n",
    "X_test.drop('dim_fare_bin', axis=1, inplace=True)\n",
    "X_test.drop('dim_age_bin', axis=1, inplace=True)\n",
    "X_test.drop('dim_deck', axis=1, inplace=True)\n",
    "X_test.drop('dim_ticket_freq', axis=1, inplace=True)\n",
    "\n",
    "df_test_trans = pd.merge(df_test_trans, df_train_trans[['dim_deck']],left_index=True,\n",
    "                         right_index=True)\n",
    "df_test_trans_interactions = \\\n",
    "    dmatrix('C(dim_deck) : C(sex)', df_test_trans,\n",
    "              return_type=\"dataframe\")\n",
    "df_test_trans_interactions.drop('Intercept', inplace=True, axis=1)\n",
    "df_test_trans = pd.concat([df_test_trans, df_test_trans_interactions], axis=1)\n",
    "\n",
    "df_test_trans.drop('sex', axis=1, inplace=True)\n",
    "df_test_trans.drop('dim_fare', axis=1, inplace=True)\n",
    "df_test_trans.drop('dim_age', axis=1, inplace=True)\n",
    "df_test_trans.drop('dim_fare_bin', axis=1, inplace=True)\n",
    "df_test_trans.drop('dim_age_bin', axis=1, inplace=True)\n",
    "df_test_trans.drop('dim_deck', axis=1, inplace=True)\n",
    "df_test_trans.drop('dim_ticket_freq', axis=1, inplace=True)\n",
    "\n",
    "# Drop interactions for testing purposes\n",
    "interactions_list = list(X_train_interactions.columns.values)\n",
    "#X_train.drop(interactions_list, axis=1, inplace=True)\n",
    "#X_test.drop(interactions_list, axis=1, inplace=True)\n",
    "#df_test_trans.drop(interactions_list, axis=1, inplace=True)\n",
    "\n",
    "# TODO - used interactions list to hardcode this, need to fix.\n",
    "rename_dict = {'C(dim_deck)[T.BDE]:C(sex)[0.0]': 'deck_BDE_male',\n",
    "            'C(dim_deck)[T.FG]:C(sex)[0.0]': 'deck_FG_male',\n",
    "            'C(dim_deck)[T.M]:C(sex)[0.0]': 'deck_M_male',\n",
    "            'C(dim_deck)[T.BDE]:C(sex)[1.0]': 'deck_BDE_female',\n",
    "            'C(dim_deck)[T.FG]:C(sex)[1.0]': 'deck_FG_female',\n",
    "            'C(dim_deck)[T.M]:C(sex)[1.0]': 'deck_M_female'}\n",
    "X_train.rename(columns = rename_dict, inplace=True)\n",
    "X_test.rename(columns = rename_dict, inplace=True)\n",
    "df_test_trans.rename(columns = rename_dict, inplace=True)\n",
    "\n",
    "# Drop is_married for testing purposes\n",
    "X_train.drop(['C(sex)[T.1.0]'], axis=1, inplace=True)\n",
    "X_test.drop(['C(sex)[T.1.0]'], axis=1, inplace=True)\n",
    "df_test_trans.drop(['C(sex)[T.1.0]'], axis=1, inplace=True)\n",
    "X_train.drop(['is_married'], axis=1, inplace=True)\n",
    "X_test.drop(['is_married'], axis=1, inplace=True)\n",
    "df_test_trans.drop(['is_married'], axis=1, inplace=True)\n",
    "\n",
    "X_train.drop('deck_BDE', axis=1, inplace=True)\n",
    "X_train.drop('deck_FG', axis=1, inplace=True)\n",
    "X_train.drop('deck_M', axis=1, inplace=True)\n",
    "\n",
    "X_test.drop('deck_BDE', axis=1, inplace=True)\n",
    "X_test.drop('deck_FG', axis=1, inplace=True)\n",
    "X_test.drop('deck_M', axis=1, inplace=True)\n",
    "\n",
    "df_test_trans.drop('deck_BDE', axis=1, inplace=True)\n",
    "df_test_trans.drop('deck_FG', axis=1, inplace=True)\n",
    "df_test_trans.drop('deck_M', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Separate continuous variables for this step, to be added back afterwards.\n",
    "X_train_con = X_train.loc[:, ['age', 'fare']]\n",
    "X_train.drop(['age', 'fare'], axis=1, inplace=True)\n",
    "# Separate continuous variables for this step, to be added back afterwards.\n",
    "X_test_con = X_test.loc[:, ['age', 'fare']]\n",
    "X_test.drop(['age', 'fare'], axis=1, inplace=True)\n",
    "# Separate continuous variables for this step, to be added back afterwards.\n",
    "df_test_trans_con = df_test_trans.loc[:, ['age', 'fare']]\n",
    "df_test_trans.drop(['age', 'fare'], axis=1, inplace=True)\n",
    "\n",
    "# Finally we scale our data - separately from categorical variables.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Fit on training data set\n",
    "names_training = list(X_train_con.columns.values)\n",
    "_ = scaler.fit(X_train_con)\n",
    "X_train_new = scaler.transform(X_train_con)\n",
    "X_train_con = pd.DataFrame(X_train_new, columns=names_training)\n",
    "\n",
    "# Apply to test data (training)\n",
    "X_test_new = scaler.transform(X_test_con)\n",
    "X_test_con = pd.DataFrame(X_test_new, columns=names_training)\n",
    "\n",
    "# Scale age and fare on final dataset to final test data\n",
    "df_test_trans_new = scaler.transform(df_test_trans_con)\n",
    "df_test_trans_con = pd.DataFrame(df_test_trans_new, columns=names_training)\n",
    "\n",
    "# Perform categorical feature selection\n",
    "X_train = X_train.astype(float)\n",
    "y_train = y_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "y_test = y_test.astype(float)\n",
    "df_test_trans =  df_test_trans.astype(float)\n",
    "\n",
    "best_feat = SelectKBest(chi2, k=15).fit(X_train, y_train)\n",
    "mask = X_train.columns.values[best_feat.get_support()]\n",
    "X_train_new = best_feat.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_new, columns=mask)\n",
    "\n",
    "X_test_new = best_feat.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_new, columns=mask)\n",
    "\n",
    "df_test_trans_new = best_feat.transform(df_test_trans)\n",
    "df_test_trans = pd.DataFrame(df_test_trans_new, columns=mask)\n",
    "\n",
    "# What are scores for the features\n",
    "for i in range(len(mask)):\n",
    "\tprint('%s: \\t\\t\\t\\t%f' % (mask[i], best_feat.scores_[i]))\n",
    "\n",
    "# plot the scores\n",
    "_ = pyplot.bar([i for i in range(len(best_feat.scores_))], best_feat.scores_)\n",
    "pyplot.show()\n",
    "\n",
    "# Add continuous variables back again.\n",
    "X_train = pd.merge(X_train, X_train_con[['age', 'fare']], left_index=True, right_index=True)\n",
    "X_test = pd.merge(X_test, X_test_con[['age', 'fare']], left_index=True, right_index=True)\n",
    "df_test_trans = pd.merge(df_test_trans, df_test_trans_con[['age', 'fare']], left_index=True,\n",
    "                         right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "df_test_trans =  df_test_trans.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final dataset for model building looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"build\" style = \"font-family:verdana; background-color:#C5D6FA\"><center>Build models\n",
    "</center></h1>\n",
    "<p><center style=\"color:#1F4BA7; font-family:cursive;\">Building a series of models and\n",
    "testing model accuracy</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start building our first model, yay! We build and test a naive logistic regression\n",
    "model - without any transformations or optimisations.\n",
    "\n",
    "The objective is to ascertain the strength of association between features and responses on\n",
    "unprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initial model\n",
    "log_reg = LogisticRegression(max_iter=2000000, fit_intercept = False)\n",
    "\n",
    "# Probability scores for test set\n",
    "y_score_init = log_reg.fit(X_train, y_train).decision_function(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_score_init)\n",
    "\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "# Accuracy before model parameter optimisation\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the accuracy measurements the baseline model performs marginally better\n",
    "than our baseline models. A C-statistic (Area Under the Curve - AUC) of 88% compared to 86%\n",
    "for the baseline model.\n",
    "\n",
    "The model has a precision of 83% which is the same as the previously obtained 83%.\n",
    "\n",
    "The sensitivity of 77% is up from 68% which means more survivors are being picked up with\n",
    "this model. Specificity us down to 83% from 86% which means the increase in accuracy is at\n",
    "the expense of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fit and check MSE before regularisation\n",
    "mlp_reg = MLPClassifier(max_iter=50000, solver=\"adam\", activation=\"tanh\", hidden_layer_sizes=(5, 5),\n",
    "                    random_state=1)\n",
    "mlp_reg = mlp_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = mlp_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy before model parameter optimisation\n",
    "print (\"Accuracy Score: %0.5f\" % accuracy_score(y_pred,y_test))\n",
    "\n",
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)\n",
    "\n",
    "# Accuracy before model parameter optimisation\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive MLP has an AUC score of 85% which is higher than the previous score of\n",
    "Regression of 79%.\n",
    "\n",
    "Let us see what the Learning Curve for the naive MLP looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Default value of 5 fold CV will be used.\n",
    "title = r\"Learning curve (MLP - Unoptimised)\"\n",
    "_ = plot_learning_curve(mlp_reg, title, X_train, y_train, cv=None, n_jobs=-1,\n",
    "                        learn_scoring=\"accuracy\", scoring_title=\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning curve for the un-optimised MLP shows the following:\n",
    "\n",
    "- The MLP predicts 100% correctly for 1 example in training. This makes sense. With only one\n",
    " training sample the validation accuracy is around 0.65, which is actually not bad for 1\n",
    " training example.\n",
    "- The model learns consistently and fast over the first 400 observations, validation\n",
    "accuracy increases from 0.65 to 0.83.\n",
    "- The model accuracy on the training set reduces from 1 to around 0.85 during this interval,\n",
    "which is not a significant drop given the increase in training set size.\n",
    "- The accuracy on the training set increases to close to 0.9 towards 500 training samples\n",
    "and continues to climb (the validation accuracy at this point however decreases i.e.\n",
    "inversely proportional to the training accuracy which indicates over-fitting).\n",
    "\n",
    "Base on these observations we can draw the following conclusions:\n",
    "\n",
    "- The model performs very well on a small dataset with only a few variables.\n",
    "- There is scope for an increase in learning rate during the first 400 training samples.\n",
    "Better feature engineering is a possible means of attaining an increased learning rate.\n",
    "- The model overfits after 400 training samples. Regularisation or other measures to avoid\n",
    "overfitting could maybe help. It would help to have validation accuracy increase along with\n",
    "training post 400 samples, as this is quite a small sample size to begin with.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimised MLP\n",
    "\n",
    "We now optimise both the number of hidden layers, nodes as well the regularisation parameter\n",
    " <i>alpha</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Optimise numbers of nodes on both layers\n",
    "validation_scores = {}\n",
    "print(\"Nodes |Validation\")\n",
    "print(\"      | score\")\n",
    "\n",
    "for hidden_layer_size in [(i,j) for i in range(2,6) for j in range(2,6)]:\n",
    "\n",
    "    reg = MLPClassifier(max_iter=1000000, hidden_layer_sizes=hidden_layer_size, random_state=1)\n",
    "\n",
    "    score = cross_val_score(estimator=reg, X=X_train, y=y_train, cv=2)\n",
    "    validation_scores[hidden_layer_size] = score.mean()\n",
    "    print(hidden_layer_size, \": %0.5f\" % validation_scores[hidden_layer_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check scores\n",
    "print(\"The highest validation score is: %0.4f\" % max(validation_scores.values()))\n",
    "optimal_hidden_layer_size = [name for name, score in validation_scores.items()\n",
    "                              if score==max(validation_scores.values())][0]\n",
    "print(\"This corresponds to nodes\", optimal_hidden_layer_size )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we optimise the neural network regularisation parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Select range over which to find regularisation parameter - exponential used for even\n",
    "# distribution of values\n",
    "reg_par = [np.e**n for n in np.arange(-2,4,0.5)]\n",
    "\n",
    "validation_scores = {}\n",
    "print(\" alpha  |  Accuracy\")\n",
    "for param in reg_par:\n",
    "    reg = MLPClassifier(max_iter=1000000, solver=\"adam\", activation=\"tanh\",\n",
    "                        hidden_layer_sizes=optimal_hidden_layer_size, alpha=param, random_state=1)\n",
    "    score = cross_val_score(estimator=reg, X=X_train, y=y_train, cv=2, scoring=\"accuracy\")\n",
    "    validation_scores[param] = score.mean()\n",
    "    print(\"%0.5f |  %s\" % (param, score.mean()))\n",
    "\n",
    "# Plot the accuracy function against regularisation parameter\n",
    "plt.plot([np.log(i) for i in validation_scores.keys()], list(validation_scores.values()));\n",
    "plt.xlabel(\"Ln of alpha\");\n",
    "plt.ylabel(\"Accuracy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest cross-validation accuracy score and hence the value to use for the `alpha` parameter\n",
    "is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_score = ([np.log(name) for name, score in validation_scores.items() if score==max\n",
    "(validation_scores.values())][0])\n",
    "# Find lowest value.\n",
    "print(\"The highest accuracy score is: %s\" % (max(validation_scores.values())))\n",
    "print(\"This corresponds to regularisation parameter e**%s\" % max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE after regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fit data with the best parameter\n",
    "mlp_reg_optim = MLPClassifier(max_iter=1000000, solver=\"adam\", activation=\"tanh\",\n",
    "                    hidden_layer_sizes=optimal_hidden_layer_size, alpha=np.e**(max_score),\n",
    "                              random_state=1)\n",
    "\n",
    "mlp_reg_optim.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = mlp_reg_optim.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy after model parameter optimisation\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_pred)\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimised MLP has an AUC score of 78% which is higher than the previous score\n",
    "of 77%. This is encouraging as this was also the model that fared best on the public data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Default value of 5 fold CV will be used.\n",
    "title = r\"Learning curve (MLP - Unoptimised)\"\n",
    "_ = plot_learning_curve(mlp_reg_optim, title, X_train, y_train, cv=None, n_jobs=-1,\n",
    "                        learn_scoring=\"accuracy\", scoring_title=\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning curve for the optimised MLP shows the following:\n",
    "\n",
    "- Regularisation decreases 100% accuracy on 1 training sample to just below 0.9, which shows\n",
    " regularisation is working well.\n",
    "- The training accuracy drops at the same rate but drops to below 0.86 which is where it\n",
    "turned before.\n",
    "- The validation set accuracy now drops at around 300 samples, which is earlier than before.\n",
    "- The validation accuracy increase post 400 samples in in unison with the training accuracy.\n",
    "\n",
    "Based on these observations we can draw the following conclusions:\n",
    "\n",
    "- Validation resulted in the accuracy of the model increasing beyond 400 samples, which\n",
    "shows that over-fitting has been addressed to some extent.\n",
    "- More data at this point would benefit the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_scores, test_scores = validation_curve(mlp_reg_optim, X_train, y_train, \"alpha\",\n",
    "                                             reg_par, cv=None, scoring=\"accuracy\")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Reverse scores to plot increasing complexity\n",
    "train_scores_mean_rev = train_scores_mean[::-1]\n",
    "train_scores_std = train_scores_std[::-1]\n",
    "test_scores_mean_rev = test_scores_mean[::-1]\n",
    "test_scores_std = test_scores_std[::-1]\n",
    "reg_par_rev = reg_par[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "# Plot mean accuracy scores for training and testing scores\n",
    "_ = ax.plot(reg_par_rev, train_scores_mean_rev, label = \"Training Score\", color = 'b')\n",
    "_ = ax.plot(reg_par_rev, test_scores_mean_rev, label = \"Cross Validation Score\", color = 'g')\n",
    "\n",
    "# Creating the plot\n",
    "_ = ax.set_xlim(20, 0)\n",
    "_ = ax.set_title(\"Validation Curve - MLP regularisation optimisation\")\n",
    "_ = ax.set_xlabel(\"Alpha value\")\n",
    "_ = ax.set_ylabel(\"Accuracy\")\n",
    "\n",
    "_ = plt.tight_layout()\n",
    "_ = plt.legend(loc = 'best')\n",
    "_ = plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation curve based on training and testing set validation shows that the optimal\n",
    "parameter value of 1 previously attained with Cross Validation looks accurate.\n",
    "\n",
    "The curve is however disappointing in that the validation curve diverges from the training\n",
    "curve at a value of around 12.5 and then doesn't really increase convincingly afterwards.\n",
    "From this curve it seems as if more needs to be done to reduce over-fitting of this model.\n",
    "\n",
    "One possible option is to drop features which introduce multi-collinearity in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Decision Tree\n",
    "\n",
    "We now build a naive Decision Tree to see it performs against the previous models. We also use\n",
    "the Decision Tree to calculate feature importance. This will provide us with a better feeling for\n",
    " strength of association between features and the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fit a Decision Tree to data\n",
    "samples = [sample for sample in range(1,30)]\n",
    "validation_scores = []\n",
    "for sample in samples:\n",
    "    classifier1 = DecisionTreeClassifier(random_state=1, min_samples_leaf=sample)\n",
    "    score = cross_val_score(estimator=classifier1, X=X_train, y=y_train, cv=5)\n",
    "    validation_scores.append(score.mean())\n",
    "\n",
    "# Obtain the minimum leaf samples with the highest validation score\n",
    "samples_optimum = samples[validation_scores.index(max(validation_scores))]\n",
    "\n",
    "classifier2 = DecisionTreeClassifier(random_state=0, min_samples_leaf=samples_optimum)\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importances for the Decision Tree is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols_model = X_train.columns.to_list()\n",
    "\n",
    "importances = np.array(classifier2.feature_importances_)\n",
    "feature_list = np.array(cols_model)\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importances):\n",
    "\tprint('Feature: %10s\\tScore:\\t%.5f' % (feature_list[i],v))\n",
    "# plot feature importance\n",
    "sorted_ID=np.array(np.argsort(importances)[::-1])\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.xticks(rotation='vertical')\n",
    "_ = plt.bar(feature_list[sorted_ID], importances[sorted_ID]);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have an interesting turn of events. The previously most important features was sex,\n",
    "but has now been replaced by title_Mr. Passenger class and family size are in 2nd and 3rd\n",
    "places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Probability scores for test set\n",
    "y_pred = classifier2.predict(X_test)\n",
    "\n",
    "accuracy_score(y_pred,y_test)\n",
    "\n",
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_pred)\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree obtained an AUC score of 75% which is lower than the previous score of\n",
    "77%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Random Forest\n",
    "Now we build a Random Forest and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(criterion= 'gini', random_state=0)\n",
    "rand_forest.fit(X_train, y_train)\n",
    "\n",
    "# Probability scores for test set\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_pred)\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest obtained an AUC score of 83% which is higher than the previous score\n",
    "obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Default value of 5 fold CV will be used.\n",
    "title = r\"Learning curve (Random Forest - Unoptimised)\"\n",
    "_ = plot_learning_curve(rand_forest, title, X_train, y_train, cv=None, n_jobs=-1,\n",
    "                        learn_scoring=\"accuracy\", scoring_title=\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning curve for the un-optimised Random Forest shows the following:\n",
    "\n",
    "- As for the un-optimised MLP the un-optimised Random Forest has a 100% accuracy on one\n",
    "training sample for the training set, which makes sense.\n",
    "- The accuracy for one training sample on the validation set is around 75% which is better\n",
    "than the MLP.\n",
    "- The model shows large variance which is expected. Optimisation will assist with this. The\n",
    "training set obtains an accuracy of above 90%.\n",
    "- The maximum validation set accuracy is just above 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimised Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(max_features='auto')\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10],\n",
    "               \"min_samples_split\" : [2, 4, 10, 12], \"n_estimators\": [50, 100, 400, 700]}\n",
    "gs = GridSearchCV(estimator=rand_forest, param_grid=param_grid, scoring='accuracy', cv=3,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Final prediction - MLP\n",
    "#rand_forest = RandomForestClassifier(criterion= 'gini', min_samples_leaf=5,\n",
    "#                                     min_samples_split=2, n_estimators=100, random_state=0)\n",
    "rand_forest = RandomForestClassifier(criterion= 'entropy', min_samples_leaf=5,\n",
    "                                     min_samples_split=4, n_estimators=100, random_state=0)\n",
    "rand_forest.fit(X_train, y_train)\n",
    "#rand_forest.fit(x_train_prev, y_train)\n",
    "\n",
    "# Probability scores for test set\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "#y_pred = rand_forest.predict(x_test_prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "importances = np.array(rand_forest.feature_importances_)\n",
    "feature_list = np.array(X_train.columns)\n",
    "importances = np.array(importances)\n",
    "sorted_ID=np.array(np.argsort(importances))\n",
    "reverse_features = feature_list[sorted_ID][::-1]\n",
    "reverse_importances = importances[sorted_ID][::-1]\n",
    "\n",
    "for i,v in enumerate(reverse_importances):\n",
    "    print('Feature: %20s\\tScore:\\t%.5f' % (reverse_features[i],v))\n",
    "\n",
    "# Plot feature importance\n",
    "#sorted_ID=np.array(np.argsort(scores)[::-1])\n",
    "#sns.set(font_scale=1);\n",
    "_ = plt.figure(figsize=[10,10]);\n",
    "_ = plt.xticks(rotation='horizontal', fontsize=20)\n",
    "_ = plt.barh(feature_list[sorted_ID], importances[sorted_ID], align='center');\n",
    "_ = plt.yticks(fontsize=20)\n",
    "_ = plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_pred,y_test)\n",
    "\n",
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_pred)\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Default value of 5 fold CV will be used.\n",
    "title = r\"Learning curve (Random Forest - Optimised)\"\n",
    "_ = plot_learning_curve(rand_forest, title, X_train, y_train, cv=None, n_jobs=-1,\n",
    "                        learn_scoring=\"accuracy\", scoring_title=\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning curve for the Optimised Random Forest shows the following:\n",
    "\n",
    "- The accuracy for training starts at around 0.81 for the Random Forest. Optimisation has a\n",
    "marked effect for accuracy on one training sample.\n",
    "- Validation accuracy increases rapidly to above 0.8 before 200 samples are reached, which\n",
    "shows variance has reduced substantially.\n",
    "- Accuracy on validation remain at around 0.82 for the remainder of training samples.\n",
    "- From 200 - 500 samples accuracy on the training set also remains constant at around 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"conclusion\" style = \"font-family:verdana; background-color:#C5D6FA\"><center>Conclusion</center></h1>\n",
    "<a class=\"anchor-link\" href=\"https://www.kaggle.com/lourenswalters/i-titanic-baseline-models-0-78#conclusion\"></a>\n",
    "<p><center style=\"color:#1F4BA7; font-family:cursive;\">What have we learnt?</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that there is a strong signal in the data with regards to correlation with survival rate.\n",
    "Counter-intuitively, the Logistic Regression proved to be the best model scoring approximately 86% for the\n",
    "C-Statistic. The Random Forest classifier is second with 84% for the C-Statistic. We would have expected the Random\n",
    "Forest to outperform the Logistic Regression given all the categorical variables. The strong correlation between age,\n",
    " fare and survival probably outweighed the categorical variable influence on survival rate. We expect the Random\n",
    " Forest to improve once we add names and cabins back into the mix. Also, in the name of speed we used scaled values\n",
    " for the Random Forest and it might do better on the original data. We will need to test this in the next notebook.\n",
    "\n",
    "All in all, this was an insightful analysis. We found that the few variables we have are very strong predictors for\n",
    "survival. In a real world setting further analysis is probably not necessary, as the gains from over-engineering\n",
    "variables for a model which does not have much practical value is probably not worthwhile.\n",
    "\n",
    "This is however an educational exercise and hence we will go ahead and try to squeeze more accuracy and insight out\n",
    "of the remaining variables. Focusing more on the insight than accuracy, as at this point the model is probably\n",
    "accurate enough for any practical application that might exist (which there obviously doesn't!).\n",
    "\n",
    "On to the next notebook!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Gender submission - Score: 0.77\n",
    "\n",
    "# Final prediction - Random Forest - Score:  0.79665\n",
    "y_pred = rand_forest.predict(df_test_trans)\n",
    "y_pred = y_pred.astype(int)\n",
    "\n",
    "#Prepare submission code\n",
    "my_submission = pd.DataFrame({'PassengerId': df_orig.passenger_id, 'Survived': y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission_rand_forest.csv', index=False)\n",
    "\n",
    "# Final prediction - MLP (optimised) - Score: ?\n",
    "#mlp_reg_optim.fit(X, y)\n",
    "y_pred = mlp_reg_optim.predict(df_test_trans)\n",
    "\n",
    "#Prepare submission code\n",
    "my_submission = pd.DataFrame({'PassengerId': df_orig.passenger_id, 'Survived': y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission_mlp_optim.csv', index=False)\n",
    "\n",
    "# TODO: Final prediction - MLP (non-optimised) - Score: ?\n",
    "y_pred = mlp_reg.predict(df_test_trans)\n",
    "\n",
    "#Prepare submission code\n",
    "my_submission = pd.DataFrame({'PassengerId': df_orig.passenger_id, 'Survived': y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission_mlp.csv', index=False)\n",
    "\n",
    "# Final prediction - Logistic Regression - Score: ?\n",
    "y_pred = log_reg.predict(df_test_trans)\n",
    "\n",
    "#Prepare submission code\n",
    "my_submission = pd.DataFrame({'PassengerId': df_orig.passenger_id, 'Survived': y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission_logreg.csv', index=False)\n",
    "\n",
    "# Final prediction - Decision Tree - Score: ?\n",
    "y_pred = classifier2.predict(df_test_trans)\n",
    "\n",
    "#Prepare submission code\n",
    "my_submission = pd.DataFrame({'PassengerId': df_orig.passenger_id, 'Survived': y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission_dec_tree.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Prepare submission code\n",
    "#my_submission = pd.DataFrame({'PassengerId': df_orig.passenger_id, 'Survived': y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "#my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}